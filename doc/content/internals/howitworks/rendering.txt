Rendering
<!--@weight=500-->
<p>This part describes how the rendering in Alithia Engine is performed. The rendering is broken in several stages and each one will be discussed separately. The stages are visibility, culling, bucket filling and finally bucket rendering. This part does not deal with <span class="caps">HUD</span> or <span class="caps">GUI</span> rendering. For <span class="caps">HUD</span> the rendering is straightforward, <br />
while <span class="caps">GUI</span> rendering will be discussed in another point of this document.</p>

<h2>Overview</h2>

<p>The engine tries to minimize the preprocessing steps required to render the map, which allows for faster content creation and testing cycles. To do this, it imposes some restrictions on how the world is represented and rendered. The restriction is simple: the world is defined by a 2D grid with each cell having two height values &#8211; one for the floor and one for the ceiling &#8211; thus forming a world made up of two height fields. The world has a single world-sized lightmap with one lumel for each cell. The lights inside the world are used to compute the lightmap at map load time. Even if the world and lightmap are essentially 2D, the lights and entities use 3D coordinates, so proper 3D rendering and lighting can be used (later the entities will also contain optional collision and occlusion geometry, so more complex 3D structures will be possible &#8211; eventually).</p>

<p>To speed up the rendering process and be modern <span class="caps">GPU</span> friendly without hogging older <span class="caps">GPU</span>s with unnecessary data, the world is broken in clusters which are typically sized at 16x times of a map cell (that is, one cluster contains 16&#215;16 map cells). The clusters are also used to group entities for visibility and collision detection: each cluster has a list of entities which are inside the cluster so if a cluster is determined to be visible, the entities inside the cluster are also believed to be visible. Before rendering a cluster, the cluster is converted to one or more display lists with each list containing only vertex data (this kind of display list is very fast on modern hardware, especially nVidia <span class="caps">GPU</span>s).</p>

<p>The engine renders both the world and the entities at about the same time and tries to minimize bindings when rendering the world. To do that, it uses what i call, a bucket system where each bucket contains a single texture reference and one or more display lists which contain vertex data to be rendered using this texture. To avoid any uneccessary sorting, each texture also contains a bucket reference and the bucket rendering process simply skips the empty buckets (it is supposed that a map will contain similar buckets grouped together &#8211; at map loading time, the bucket cache will be cleaned to avoid too many holes in the bucket array).</p>

<h2>Visibility</h2>

<p>At the beginning of the frame, the engine tries to figure out what is potentially visible. A large part of the data this process returns will be discarded in the culling step below, however in a highly occluded map, the larger part of the map will be ignored thanks to this step. The visibility step works in the 2D grid only and assumes a &#8220;camera&#8221; that can see at 360 degrees. It works by sending rays from the camera&#8217;s cell to all directions inside the 2D grid. The ray is marched inside the cell with one step per cell and stops once an occluding cell is found (an occluding cell is one with the <code>CF_OCCLUDER</code> flag). The non-occluding cells are considered as visible and the cluster they belong to is marked as visible.</p>

<p>The ray marching method is based on <em>Bresenham&#8217;s line algorithm</em> and it always starts from the first given point. It has a small inaccuracy at points which are far away from the camera, so when a cluster is marked as visible, the cluster which is next to it in the X direction is always marked as visible to cover for possible errors. The culling process below will cut some of these invisible clusters which are outside the camera&#8217;s frustum.</p>

<p>Currently the visibility method considers all cells as flat &#8211; that is, it doesn&#8217;t take in account the cell height values. So the cells considered as visible are those who can be seen from the camera&#8217;s cell and invisible those who have an occluder cell between them and the camera&#8217;s cell, disregarding the cell heights. A later optimization on this might be to take in account the cell heights when computing the visible cells, but this might actually slow down the visibility algorithm due to cache misses. Currently the engine uses a separate bit-map for the occlusion flag which uses one bit per cell to keep as much information in the <span class="caps">CPU</span> cache as possible. The use of this bit-map was one of the optimizations which increased dramatically the rendering speed in an Intel Atom-based Acer Aspire One (and reportedly works even with a 1999 Intel i810 GPU!).</p>

<h2>Culling</h2>

<p>The visiblity step above creates a list of potentially visible clusters. However most of these clusters are outside the camera&#8217;s viewing frustum, so they need to be ignored. The culling is done in 3D space using the cluster&#8217;s bounding box which is calculated using the cells&#8217; coordinates inside the grid for the X and Z coordinates and the minimum and maximum heights inside the cell geometry for the Y coordinates.</p>

<p>As the clusters are found visible (and not culled), a visible entity list is filled with the entities found inside the clusters. This list is used for filling the buckets (see below) with the entity geometry and later drawing the entity shadows. Also the cluster is added in a &#8216;visible cluster&#8217; array (<code>vcluster</code>) which is used later to draw the decals (this was added later and in the future the rendering process might be simplified thanks to this array).</p>

<h2>Filling</h2>

<p>Once what is really visible is found (with a few errors, of course, but hopefully they are on the good side), the engine starts to fill the geometry buckets. These buckets contain a single texture and one or more display lists (actually they can contain no display lists at all, but empty buckets are ignored). When rendering, the texture&#8217;s bucket reference is used by the engine to decide in which bucket the display list in question (we&#8217;ll discuss shortly how these lists are made) will be put. If the texture has no bucket reference, a new bucket is allocated for that texture in the global bucket array and the list with that texture is put there. At the end of this process, all buckets are filled with display lists which use the texture referenced in each bucket and each texture has only a single bucket.</p>

<p>The display lists mentioned only have vertex information &#8211; position, normals, UV coords, etc. Anything that can go between a <code>glBegin</code> and <code>glEnd</code> basically (including one call of each). These can be as fast or &#8211; in nVidia hardware &#8211; faster than vertex arrays, <span class="caps">VBO</span>s, etc (in dumb implementations they can be also slower though, but so far i&#8217;ve seen none of these). These lists are generated from the clusters and the entities. The entity display lists are straightforward copies of the entity&#8217;s model mesh. For these lists the bucket also contains transformation information for the display list so it can render the list at the correct place for each entity (since a display list is associated with a model and not an entity and entities can share the same model, we can&#8217;t bake this information in the display list).</p>

<p>For the display lists created from clusters the process is a little more complex and involves two steps. Since a cluster can contain more than one texture, the cluster is broken in several cluster parts with one texture and one display list per part. If a cluster has these parts built, it simply sends the display lists inside these parts to the buckets. Otherwise the geometry for the parts is built and then the lists made by the building process is sent to the buckets. The first step to build these display lists is to calculate the mesh for the cells inside the cluster based on the cell heights and flags. The second step is to optimize this mesh to combine similar quads. This second step is another optimization which brought the engine from barely realtime to playable speeds in an Intel <span class="caps">GMA</span> 950 found in my Acer Aspire One. </p>

<p>The cell&#8217;s geometry is calculated by first calculating the top (ceiling) and bottom (floor) quads for each cell. These quads are calculated in the <code>cell_vertices</code> function. The (badly named) <code>draw_cell</code> function uses this function to calculate these quads and the cap quads &#8211; if needed &#8211; which are used to close the holes between two cells which have different heights (the cap quads are the only quads you see in walls or columns which have the same height for their floor and ceiling). These quads are added in a bucket-like structure inside each cluster called partbuild &#8211; this is a temporary structure to hold cluster parts while these parts are being built. When all cells in a cluster have their geometry calculated, these structures are converted to cluster parts and the optimization step is performed.</p>

<p>The optimization step uses a simple mesh simplification algorithm which takes advantage of the fact that all quads are squares and checks all coplanar quads for common edges. When a common edge is found, the non-common vertices of each of the two quads are used to build a new quad which replaces the first one and the second quad is removed. This process is repeated for all quads inside the cell until no quads are combined. This step can reduce the vertex count in a cell from 2048 down to 8 for cells which contain only flat geometry. In a big room made of many flat clusters, this saves a great number of vertices which can be the difference between realtime and really crawling in a slow <span class="caps">GPU</span> such as <span class="caps">GMA</span> 950.</p>

<h2>Bucket Rendering</h2>

<p>Once all buckets are filled with the scene&#8217;s geometry, the buckets are rendered. The global bucket array is scanned for non-empty buckets and for each bucket its texture is bound and the display lists inside the bucket are called for rendering. By default the buckets use multitexturing to combine the world textures (the textures defined in each cell) with the lightmap. Some bucket entries however, contain a transformation matrix for one or more of the bucket&#8217;s list. For these lists, the second texture (lightmap) is temporary disabled and a directional light is placed above the geometry in the display list using the color from the nearest lightmap lumel for both the diffuse and ambient light components (the ambient component is set to 1/3 of the diffuse component).</p>

<h2>Decals</h2>

<p>Once the buckets have been rendered, the next step is to render the decals. These are simple textured quads references in a decals list inside the clusters. For this, the <code>vcluster</code> array is used.</p>

<h2>Shadows</h2>

<p>After the buckets, the entity shadows are rendered using the visible entity list. The shadows are rendered using the stencil buffer and a simple planar projection of the shadow to the ground in the XZ plane. The shadow&#8217;s level (its Y value) is calculated using the floor height of cell nearest to the entity&#8217;s origin point. Like the models themselves, the shadow geometry is also saved in a display list (however, at the future this might be changed to use the same display list with a zero Y scale).</p>

<p>The shadow geometry is actually rendered in the stencil buffer with depth writes and color writes disabled, depth testing enabled and the stencil operation to set the affected pixels to 1 while the rest are set to 0. Then when all shadows are rendered in the stencil buffer, a fullscreen quad is rendered with the stencil test to allow only pixels with their value to 1. The fullscreen quad is alpha blended with an alpha value of 0.5, this making nice semi-transparent and intersecting shadows without artifacts (except the artifact of being planar of course).</p>

<p>As a side note, i have written a <a target='_top' href="http://www.indiedb.com/members/badsector/tutorials/cheap-shadows">tutorial on cheap shadows</a> in IndieDB, like those used in Alithia Engine.</p>
